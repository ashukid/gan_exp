{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-05e9bfcd3c17>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2f620a2ac8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/mnist\")\n",
    "plt.imshow(mnist.train.images[4].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wil take a random noise (z) and return the reconstructed image\n",
    "def GN(z,reuse=None):\n",
    "    \n",
    "    with tf.variable_scope('gen',reuse=reuse):\n",
    "        layer1 = tf.layers.dense(z,256,activation=tf.nn.relu)\n",
    "        layer2 = tf.layers.dense(layer1,512,activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(layer2,784,activation=tf.nn.tanh)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will take an image x and will predict whether that belongs\n",
    "# to data sample or random sample\n",
    "def DN(X,reuse=None):\n",
    "    \n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        layer1 = tf.layers.dense(X,256,activation=tf.nn.relu)\n",
    "        layer2 = tf.layers.dense(layer1,128,activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(layer2,1,activation=tf.nn.sigmoid)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining placeholders for real image and noise input\n",
    "with tf.name_scope('placeholders'):\n",
    "    real_image = tf.placeholder(tf.float32,shape=(None,784))\n",
    "    z = tf.placeholder(tf.float32,shape=(None,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking input from the Discriminator and Generator networks\n",
    "with tf.name_scope('logits'):\n",
    "    fake_image = GN(z)\n",
    "\n",
    "    real_logit = DN(real_image)\n",
    "    fake_logit = DN(fake_image,reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function \n",
    "dloss = -tf.reduce_mean(tf.log(real_logit)+tf.log(1. - fake_logit))\n",
    "gloss = -tf.reduce_mean(tf.log(fake_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the variables for separately training discriminator and generator network\n",
    "allvars = tf.trainable_variables()\n",
    "dvars = [var for var in allvars if 'dis' in var.name]\n",
    "gvars = [var for var in allvars if 'gen' in var.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining separate optimizers for discriminator and generator\n",
    "with tf.variable_scope('optimizer',reuse=tf.AUTO_REUSE):\n",
    "    \n",
    "    doptimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(dloss,var_list=dvars)\n",
    "    goptimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(gloss,var_list=gvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### global variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the global variables\n",
    "batch_size = 100\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epoch):\n",
    "        \n",
    "        # looping over the dataset\n",
    "        for i in range(mnist.train.num_examples//batch_size):\n",
    "            \n",
    "            # taking next batch of data\n",
    "            batch_data = mnist.train.next_batch(batch_size=batch_size)\n",
    "            # reshaping the batch of data\n",
    "            ximage = batch_data[0].reshape((batch_size,784))\n",
    "            # randomly sampling a noise from uniform distribution\n",
    "            xsample = np.random.uniform(-1.,1.,size=(batch_size,100))\n",
    "            \n",
    "            # optimising\n",
    "            sess.run(doptimizer,feed_dict={real_image:ximage,z:xsample})\n",
    "            sess.run(goptimizer,feed_dict={z:xsample})\n",
    "            \n",
    "            # printing the loss values\n",
    "            if(i%500==0 and epoch%10==0):\n",
    "                l1 = sess.run(dloss,feed_dict={real_image:ximage,z:xsample})\n",
    "                l2 = sess.run(gloss,feed_dict={z:xsample})\n",
    "                print(\"after {} losses : Descriptor : {} Generator : {}\\n\".format(i,l1,l2))\n",
    "        \n",
    "        print(\"On epoch {}\".format(epoch))\n",
    "        \n",
    "        # generating samples after each epoch\n",
    "        cur_sample = np.random.uniform(-1,1,size=(1,100))\n",
    "        gen_sample = sess.run(fake_image,feed_dict={z:cur_sample})\n",
    "        gen_sample = gen_sample.reshape(28,28)\n",
    "        \n",
    "        # saving the image after each epoch\n",
    "        cv2.imwrite(\"image_\"+str(epoch),gen_sample)\n",
    "        \n",
    "        # saving the model after each epoch\n",
    "        saver.save(sess,'./model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
