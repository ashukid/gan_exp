{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FROM MNIST TO CELEBA TO CATANDDOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"../data/MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(mnist.train.images[4].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image helper functions\n",
    "def convert_to_tanh(im):\n",
    "    #print(\"Converting Image in tanh range ... !\")\n",
    "    max_value = np.round(np.max(im))\n",
    "    min_value = np.round(np.min(im))\n",
    "    if(max_value == 1 and min_value == -1):\n",
    "        #print(\"Array already in tanh range\")\n",
    "        return im\n",
    "    return np.round(((im/max_value)*2)-1,decimals=2)\n",
    "\n",
    "def convert_from_tanh(im):\n",
    "    #print(\"Conveting image from tanh to 0-255 range\")\n",
    "    max_value = np.round(np.max(im))\n",
    "    return np.round(((im+1)/2)*max_value,decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architeture helper functions\n",
    "def relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def tanh(x):\n",
    "    return tf.nn.tanh(x)\n",
    "\n",
    "def lrelu(x):\n",
    "    return tf.nn.leaky_relu(x)\n",
    "\n",
    "def batch_norm(x):\n",
    "    layer = tf.layers.batch_normalization(x)\n",
    "    return layer\n",
    "\n",
    "def linear(x,out_neuron,name):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable(name='weights',shape=[x.get_shape()[1].value,out_neuron],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable(name='biases',shape=[out_neuron],initializer=tf.constant_initializer())\n",
    "        layer = tf.matmul(x,w)+b\n",
    "    return layer\n",
    "\n",
    "def conv2d(x,filter_size,in_channel,out_channel,stride,name,padding='same'):\n",
    "    # default filter size (5,5)\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable(name='kernel',shape=[filter_size,filter_size,in_channel,out_channel],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable(name='biases',shape=[out_channel],initializer=tf.constant_initializer())\n",
    "        layer = tf.nn.conv2d(x,filter=w,strides=[1,stride,stride,1],padding=padding.upper())+b\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def deconv2d(x,in_channel,out_channel,stride,name,):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable(name='kernel',shape=[5,5,out_channel,in_channel],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        out_w = x.get_shape()[1].value*stride\n",
    "        out_h = x.get_shape()[2].value*stride\n",
    "        if(x.get_shape()[0] == None):\n",
    "            print(\"Placeholder Error : Define placeholder with batch_size instead of 'None' \")\n",
    "            return None\n",
    "        # outshape needs exact integers instead on None or -1\n",
    "        out_shape = [x.get_shape()[0].value,out_w,out_h,out_channel]\n",
    "        out_shape = tf.stack(out_shape)\n",
    "        layer = tf.nn.conv2d_transpose(x,filter=w,output_shape=out_shape,strides=[1,stride,stride,1],padding='SAME')\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# image size should be multiple of 16\n",
    "image_size = 128\n",
    "image_channel = 3\n",
    "z_shape = 100\n",
    "batch_size = 32\n",
    "maxpool_stride = 2\n",
    "normal_stride = 1\n",
    "\n",
    "df_size = 5 # dsicriminator filter\n",
    "df_channel = 32\n",
    "gf_size = image_size //16 # generator filter\n",
    "gf_channel = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DN(X,reuse=None):\n",
    "    X = tf.reshape(X,shape=[-1,image_size,image_size,image_channel])\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        l1 = lrelu(conv2d(X,df_size,image_channel,df_channel,maxpool_stride,'l1'))\n",
    "        l2 = lrelu(conv2d(l1,df_size,df_channel,df_channel*2,maxpool_stride,'l2'))\n",
    "        l3 = lrelu(conv2d(l2,df_size,df_channel*2,df_channel*4,maxpool_stride,'l3'))\n",
    "        l4 = lrelu(conv2d(l3,l3.get_shape()[1],df_channel*4,1024,normal_stride,'l4','valid')) # valid padding\n",
    "        l5 = conv2d(l4,1,1024,1,normal_stride,'l5','valid') # valid padding\n",
    "        output = tf.reshape(l5,shape=[-1,1*1*1])\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "def DN_bn(X,reuse=None):\n",
    "    # no batch norm to discriminator input layer\n",
    "    X = tf.reshape(X,shape=[-1,image_size,image_size,image_channel])\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        l1 = lrelu(conv2d(X,df_size,image_channel,32,maxpool_stride,'l1'))\n",
    "        l2 = lrelu(batch_norm(conv2d(l1,df_size,32,64,maxpool_stride,'l2')))\n",
    "        l3 = lrelu(batch_norm(conv2d(l2,df_size,64,128,maxpool_stride,'l3')))\n",
    "        l4 = lrelu(batch_norm(conv2d(l3,l3.get_shape()[1],128,1024,normal_stride,'l4','valid'))) # valid padding\n",
    "        l5 = conv2d(l4,1,1024,1,normal_stride,'l5','valid') # valid padding\n",
    "        output = tf.reshape(l5,shape=[-1,1*1*1])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GN(z,reuse=None):\n",
    "    z = tf.reshape(z,shape=[-1,z_shape])\n",
    "    with tf.variable_scope('gen'):\n",
    "        l1 = relu(linear(z,gf_size*gf_size*gf_channel,'l1'))\n",
    "        l1 = tf.reshape(l1,[-1,gf_size,gf_size,gf_channel])\n",
    "        l2 = relu(deconv2d(l1,gf_channel,gf_channel//2,2,'l2'))\n",
    "        l3 = relu(deconv2d(l2,gf_channel//2,gf_channel//4,2,'l3'))        \n",
    "        l4 = relu(deconv2d(l3,gf_channel//4,gf_channel//8,2,'l4'))  \n",
    "        l5 = tanh(deconv2d(l4,gf_channel//8,image_channel,2,'l5'))\n",
    "        \n",
    "        return l5\n",
    "    \n",
    "def GN_bn(z,reuse=None):\n",
    "    # no batch norm to generator output layer\n",
    "    z = tf.reshape(z,shape=[-1,z_shape])\n",
    "    with tf.variable_scope('gen'):\n",
    "        l1 = relu(batch_norm(linear(z,gf_size*gf_size*gf_channel,'l1')))\n",
    "        l1 = tf.reshape(l1,[-1,gf_size,gf_size,gf_channel])\n",
    "        l2 = relu(batch_norm(deconv2d(ll1,gf_channel,gf_channel//2,2,'l2')))\n",
    "        l3 = relu(batch_norm(deconv2d(l2,gf_channel//2,gf_channel//4,2,'l3')))        \n",
    "        l4 = relu(batch_norm(deconv2d(l3,gf_channel//4,gf_channel//8,2,'l4')))  \n",
    "        l5 = tanh(deconv2d(l4,gf_channel//8,image_channel,2,'l5'))\n",
    "        \n",
    "        return l5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image = tf.placeholder(tf.float32,shape=[batch_size,image_size,image_size,image_channel])\n",
    "z = tf.placeholder(tf.float32,shape=[batch_size,z_shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('logits'):\n",
    "    fake_image = GN(z)\n",
    "    real_p = DN(real_image)\n",
    "    fake_p = DN(fake_image,reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('varaibles'):\n",
    "    allvars = tf.trainable_variables()\n",
    "    dvars = [var for var in allvars if 'dis' in var.name]\n",
    "    gvars = [var for var in allvars if 'gen' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan loss\n",
    "# dloss = -tf.reduce_mean( tf.log(real_p) + tf.log(1. - fake_p) )\n",
    "# gloss = -tf.reduce_mean( tf.log(fake_p) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wgan loss\n",
    "dloss = -tf.reduce_mean(real_p - fake_p)\n",
    "gloss = -tf.reduce_mean(fake_p)\n",
    "clip_d = [p.assign(tf.clip_by_value(p,-0.01,0.01)) for p in dvars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wgan-gp loss\n",
    "# dloss = -tf.reduce_mean(real_p-fake_p)\n",
    "# gloss = -tf.reduce_mean(fake_p)\n",
    "\n",
    "# alpha= tf.random_uniform(shape=[1], minval=0.,maxval=1.)\n",
    "# differences = fake_image - real_image \n",
    "# interpolates = real_image + (alpha*differences)\n",
    "# gradients = tf.gradients(DN(interpolates,name='inter_discriminator'), [interpolates])[0]\n",
    "# slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "# gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "# dloss += _lambda*gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doptimizer = tf.train.RMSPropOptimizer(learning_rate=0.00005).minimize(dloss,var_list=dvars)\n",
    "goptimizer = tf.train.RMSPropOptimizer(learning_rate=0.00005).minimize(gloss,var_list=gvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images found : 202599\n",
      "Creating batches of 32\n",
      "Done reading .. !\n"
     ]
    }
   ],
   "source": [
    "from data import *\n",
    "next_element,total_image_count,iter_init_op = get_data('../data/celebA/',image_size,image_size,image_channel,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_critic = 5\n",
    "total_epoch = 100\n",
    "generated_images = []\n",
    "dloss_x = []\n",
    "dloss_y = []\n",
    "gloss_x = []\n",
    "gloss_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Started training ... .! ----> \n",
      "\n",
      "\n",
      "On epoch : 0\n"
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(iter_init_op)\n",
    "    \n",
    "    print(\"<---- Started training ... .! ----> \\n\")\n",
    "    for epoch in range(total_epoch):\n",
    "        \n",
    "        \n",
    "        count = 0\n",
    "        iterations = 0\n",
    "        print(\"\\nOn epoch : {}\".format(epoch))\n",
    "        \n",
    "        while(iterations < total_image_count//batch_size):\n",
    "            \n",
    "            for _ in range(n_critic):\n",
    "                # get the images\n",
    "                ximage = sess.run(next_element)\n",
    "                ximage = convert_to_tanh(ximage)\n",
    "                xsample = np.random.uniform(-1.,1.,size=(batch_size,100))\n",
    "                _,_,l1= sess.run([doptimizer,clip_d,dloss],feed_dict={real_image:ximage,z:xsample})\n",
    "                count += batch_size\n",
    "                iterations += 1\n",
    "\n",
    "            for _ in range(1):\n",
    "                xsample = np.random.uniform(-1.,1.,size=(batch_size,100))\n",
    "                _,l2 = sess.run([goptimizer,gloss],feed_dict={z:xsample})\n",
    "\n",
    "                \n",
    "        print(\"after {} epoch --> losses : Descriptor : {} Generator : {}\".format(epoch,l1,l2))\n",
    "        cur_sample = np.random.uniform(-1.,1.,size=(batch_size,100))\n",
    "        gen_sample = sess.run(fake_image,feed_dict={z:cur_sample})[0]\n",
    "        dloss_x.append(epoch)\n",
    "        dloss_y.append(l1)\n",
    "        gloss_x.append(epoch)\n",
    "        gloss_y.append(l2)\n",
    "        im = convert_from_tanh(np.squeeze(gen_sample))\n",
    "        save_image = cv2.imwrite('samples/train_'+str(iterations)+'_'+str(epoch)+'.jpg',im)\n",
    "        if(not save_image):\n",
    "            print(\"Error saving image\")\n",
    "            \n",
    "        generated_images.append(im)\n",
    "        print(\"Total data read : {}\".format(count))\n",
    "        \n",
    "    print(\"\\n <----- End of Training ... ----> !!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generated_images[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(gloss_y,gloss_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "#     # saver = tf.train.Saver()\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#     print(\"Started training .... !\")\n",
    "    \n",
    "#     for epoch in range(total_epoch):\n",
    "#         if(epoch % 10 == 0):\n",
    "#             print(\"\\nOn epoch {}\".format(epoch))\n",
    "#         for i in range(mnist.train.num_examples//(batch_size*ncritic)):\n",
    "#             for _ in range(ncritic):\n",
    "#                 batch_data = mnist.train.next_batch(batch_size=batch_size)\n",
    "#                 ximage = batch_data[0].reshape((batch_size,image_size,image_size,image_channel))\n",
    "#                 ximage = convert_to_tanh(ximage)\n",
    "#                 xsample = np.random.uniform(-1.,1.,size=(batch_size,100))\n",
    "#                 sess.run([doptimizer,clip_d],feed_dict={real_image:ximage,z:xsample})\n",
    "#             for _ in range(1):\n",
    "#                 xsample = np.random.uniform(-1.,1.,size=(batch_size,100))\n",
    "#                 sess.run(goptimizer,feed_dict={z:xsample})\n",
    "                \n",
    "#             if(i%100==0):\n",
    "#                 l1 = sess.run(dloss,feed_dict={real_image:ximage,z:xsample})\n",
    "#                 l2 = sess.run(gloss,feed_dict={z:xsample})\n",
    "#                 #print(\"after {} losses : Descriptor : {} Generator : {}\".format(i,l1,l2))\n",
    "#                 dloss_x.append(l1)\n",
    "#                 dloss_y.append(epoch)\n",
    "#                 gloss_x.append(l2)\n",
    "#                 gloss_y.append(epoch)\n",
    "#         cur_sample = np.random.uniform(-1,1,size=(batch_size,100))\n",
    "#         gen_sample = sess.run(fake_image,feed_dict={z:cur_sample})[0]\n",
    "#         #gen_sample = unsqueeze_image(np.squeeze(gen_sample)).reshape(28,28)\n",
    "#         generated_images.append(gen_sample)\n",
    "#     # saver.save(sess,\"./gan/mnist_gan_500.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
